---
title: "ww_arg_4"
author: "Sooyeol Kim"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#4. Modeling

The following code was used for various modeling of the data. 

```{r r_setup, include=FALSE}
#Packages 
library("corrr") #for correlation analysis
library(ggcorrplot) #for visualizing correlation matrix
library("FactoMineR") #for multivariate exploratory data analysis
library(ggplot2) #for plotting
library("factoextra") #for visualizing outputs of PCA
library(dplyr) #for data manipulation
library(plotly) #for interactive plotting
library(caret)
library(tidyr)
```

##4.1 PCA on secondary data 

First, we need to select just quantitative data that we're looking at. 

```{r data_selection_sec}
#Missing animal as 0 
data_burden_mer$`CATTLE, INCL CALVES - INVENTORY` <- data_burden_mer$`CATTLE, INCL CALVES - INVENTORY` %>% replace_na(0)
data_burden_mer$`CHICKEN, TOTAL` <- data_burden_mer$`CHICKEN, TOTAL` %>% replace_na(0)
data_burden_mer$`HOGS - INVENTORY` <- data_burden_mer$`HOGS - INVENTORY` %>% replace_na(0)

#Checking data structure
str(data_burden_mer)

#Select for only numerical data 
pca_sec <- data_burden_mer %>%
  select(-city, -state, -site, -plant, -Region, -Division,
         -Burden_all, -Burden_bla, -Burden_col, -Burden_van, -Burden_tet,
         -nCT_svi, -nCT_eji, -RPL_EJI, -RPL_SER, -RPL_SVM, -RPL_EBM, -RPL_HVM, 
         -urban_km2, -County)

#Check for null values
colSums(is.na(pca_sec))

#Only using data with complete data 
pca_sec <- pca_sec  %>% filter(complete.cases(.)) %>%
  select(-Colistin_norm)

#Normalize 
pca_sec_norm <- scale(pca_sec)

#See how facilities with small EPIC data affect our results 
test <- data_burden_mer %>% mutate(EPIC = TotalEncounters/E_TOTPOP) %>% 
  select(city, state, site, plant, EPIC, TotalEncounters, E_TOTPOP)

test$EncounterClass <- ifelse(test$TotalEncounters < 500, "Less than 500", "500 or more")

ggplot(test, aes(x = TotalEncounters/E_TOTPOP, fill = EncounterClass)) +
  geom_histogram() + 
  scale_x_continuous(trans = 'log10', 
                     breaks = scales::trans_breaks("log10", function(x) 10^x), 
                     labels = scales::trans_format("log10", scales::math_format(10^.x))) + 
  scale_fill_manual(values = c("Less than 500" = "lightpink1", "500 or more" = "seagreen3")) +
  labs(fill = "Total Encounters")

ggplot(test, aes(x = TotalEncounters, y = E_TOTPOP)) +
  geom_point() +
  scale_x_continuous(trans = 'log10') +
  scale_y_continuous(trans = 'log10')
```

We checked for missing values since they can bias the result of PCA. There are some missing data, especially cattle (14) and hogs (25). These values were replaced with 0 since this was either no data or witheld data. The EJI columns that didn't have information for Hawaii and Alaska were also taken out, since they were measuring a lot of similar variables as the SVI anyways (163 > 162). 

Although some of the data was already normalized (by population, or in the form of index), the whole matrix was normalized in the context of this dataset for PCA. 

```{r pca_sec}
#Applying PCA
pca_sec_res <- princomp(pca_sec_norm)
summary(pca_sec_res)

#Visualize using Scree plot
fviz_eig(pca_sec_res, addlabels = TRUE, ncp = 20)

#Visualize using biplot of attributes
biplot_sec <- fviz_pca_var(pca_sec_res)
ggplotly(biplot_sec)
fviz_pca_var(pca_sec_res, axes = c(3, 4), repel = TRUE)

#Contribution of each variable
fviz_cos2(pca_sec_res, choice = "var", axes = 1:2)

#Biplot with cos2 
fviz_pca_var(pca_sec_res, col.var = "cos2",
             gardient.cols = c("black", "orange", "blue"),
             repel = TRUE)

```

The first few PCs don't explain the majority of the variance in the data, which may mean that there are underlying structure of the data that's not captured by linear combinations, such as collinearity (which is to be expected since a lot of the variables measure the same thing and they did fall on similar spots in the PCA). 

Using FAMD on the data - turn variables into categorical
```{r}
#Number of hospitals 


```

## 4.2 PCA on ARG data 

```{r}
#Make into wide dataframe 
data_11_wide <- data_11_sum %>% 
  ungroup() %>%
  select(plant, target, mean_ARG_S) %>%
  pivot_wider(names_from = target, values_from = mean_ARG_S)

#Checking data structure
str(data_11_wide)

#Select for only numerical data 
pca_ARG <- data_11_wide %>%
  select(-plant)

#Check for null values
colSums(is.na(pca_ARG))

#Only using data with complete data 
pca_ARG <- pca_ARG  %>% filter(complete.cases(.))

#Normalize 
pca_ARG_norm <- scale(pca_ARG)

#Applying PCA
pca_ARG_res <- princomp(pca_ARG_norm)
summary(pca_ARG_res)

#Visualize using Scree plot
fviz_eig(pca_ARG_res, addlabels = TRUE, ncp = 20)

#Visualize using biplot of attributes
fviz_pca_var(pca_ARG_res)

#Contribution of each variable
fviz_cos2(pca_ARG_res, choice = "var", axes = 1:2)

#Biplot with cos2 
fviz_pca_var(pca_ARG_res, col.var = "cos2",
             gardient.cols = c("black", "orange", "blue"),
             repel = TRUE)

#Collinearity 
cor(pca_ARG)

cor_all <- data_burden_mer %>%
  select(-city, -state, -site, -plant, 
         -nCT_svi, -nCT_eji, -urban_km2, -County,
         -RPL_THEME1, -RPL_THEMES, -RPL_THEME3,
         -RPL_EJI, -RPL_SER, -RPL_SVM,
         -count_children, -total_hospitals, 
         -count_military, -count_psychiatric,
         -count_generalacutecare,
         -count_nursing_home, -count_assisted_living,
         -count_NA,
         -E_TOTPOP, -E_HH, -E_HU,
         -PROP_HISP, -PROP_LIMENG)

#Only using data with complete data 
cor_all <- cor_all  %>% filter(complete.cases(.)) %>%
  select(-Colistin_norm)

collinearity_all <- cor(scale(cor_all))

high_cor <- findCorrelation(collinearity_all, cutoff = 0.8, verbose = TRUE)

```